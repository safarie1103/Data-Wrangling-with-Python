{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mutiline_text = \"\"\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
    "\n",
    "However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.\n",
    "\n",
    "\"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\"\n",
    "\n",
    "Mr. Bennet replied that he had not.\n",
    "\n",
    "\"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"\n",
    "\n",
    "Mr. Bennet made no answer.\n",
    "\n",
    "\"Do you not want to know who has taken it?\" cried his wife impatiently.\n",
    "\n",
    "\"You want to tell me, and I have no objection to hearing it.\"\n",
    "\n",
    "This was invitation enough.\n",
    "\n",
    "\"Why, my dear, you must know, Mrs. Long says that Netherfield is taken by a young man of large fortune from the north of England; that he came down on Monday in a chaise and four to see the place, and was so much delighted with it, that he agreed with Mr. Morris immediately; that he is to take possession before Michaelmas, and some of his servants are to be in the house by the end of next week.\"\n",
    "\n",
    "\"What is his name?\"\n",
    "\n",
    "\"Bingley.\"\n",
    "\n",
    "\"Is he married or single?\"\n",
    "\n",
    "\"Oh! Single, my dear, to be sure! A single man of large fortune; four or five thousand a year. What a fine thing for our girls!\"\n",
    "\n",
    "\"How so? How can it affect them?\"\n",
    "\n",
    "\"My dear Mr. Bennet,\" replied his wife, \"how can you be so tiresome! You must know that I am thinking of his marrying one of them.\"\n",
    "\n",
    "\"Is that his design in settling here?\"\n",
    "\n",
    "\"Design! Nonsense, how can you talk so! But it is very likely that he may fall in love with one of them, and therefore you must visit him as soon as he comes.\"\n",
    "\n",
    "\"I see no occasion for that. You and the girls may go, or you may send them by themselves, which perhaps will be still better, for as you are as handsome as any of them, Mr. Bingley may like you the best of the party.\"\n",
    "\n",
    "\"My dear, you flatter me. I certainly have had my share of beauty, but I do not pretend to be anything extraordinary now. When a woman has five grown-up daughters, she ought to give over thinking of her own beauty.\"\n",
    "\n",
    "\"In such cases, a woman has not often much beauty to think of.\"\n",
    "\n",
    "\"But, my dear, you must indeed go and see Mr. Bingley when he comes into the neighbourhood.\"\n",
    "\n",
    "\"It is more than I engage for, I assure you.\"\n",
    "\n",
    "\"But consider your daughters. Only think what an establishment it would be for one of them. Sir William and Lady Lucas are determined to go, merely on that account, for in general, you know, they visit no newcomers. Indeed you must go, for it will be impossible for us to visit him if you do not.\"\n",
    "\n",
    "\"You are over-scrupulous, surely. I dare say Mr. Bingley will be very glad to see you; and I will send a few lines by you to assure him of my hearty consent to his marrying whichever he chooses of the girls; though I must throw in a good word for my little Lizzy.\"\n",
    "\n",
    "\"I desire you will do no such thing. Lizzy is not a bit better than the others; and I am sure she is not half so handsome as Jane, nor half so good-humoured as Lydia. But you are always giving her the preference.\"\n",
    "\n",
    "\"They have none of them much to recommend them,\" replied he; \"they are all silly and ignorant like other girls; but Lizzy has something more of quickness than her sisters.\"\n",
    "\n",
    "\"Mr. Bennet, how can you abuse your own children in such a way? You take delight in vexing me. You have no compassion for my poor nerves.\"\n",
    "\n",
    "\"You mistake me, my dear. I have a high respect for your nerves. They are my old friends. I have heard you mention them with consideration these last twenty years at least.\"\n",
    "\n",
    "\"Ah, you do not know what I suffer.\"\n",
    "\n",
    "\"But I hope you will get over it, and live to see many young men of four thousand a year come into the neighbourhood.\"\n",
    "\n",
    "\"It will be no use to us, if twenty such should come, since you will not visit them.\"\n",
    "\n",
    "\"Depend upon it, my dear, that when there are twenty, I will visit them all.\"\n",
    "\n",
    "Mr. Bennet was so odd a mixture of quick parts, sarcastic humour, reserve, and caprice, that the experience of three-and-twenty years had been insufficient to make his wife understand his character. Her mind was less difficult to develop. She was a woman of mean understanding, little information, and uncertain temper. When she was discontented, she fancied herself nervous. The business of her life was to get her daughters married; its solace was visiting and news. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutiline_text = \"\"\"For data to be useful and meaningful, it must be curated and refined. Data Wrangling with Python teaches you all the core ideas behind these processes\n",
    "and equips you with knowledge about the most popular tools and techniques in the domain.\n",
    "\n",
    "The book starts with the absolute basics of Python, focusing mainly on data structures, and then quickly jumps into the NumPy and pandas libraries \n",
    "as the fundamental tools for data wrangling. We emphasize why you should stay away from the traditional way of data cleaning, as done in other languages, \n",
    "and take advantage of the specialized pre-built routines in Python. Thereafter, you will learn how, using the same Python backend, you can extract and \n",
    "transform data from a diverse array of sources, such as the internet, large database vaults, or Excel financial tables. Then, you will also learn how to handle missing or incorrect data, and reformat it based on the requirements from the downstream analytics tool. You will learn about these concepts through real-world\n",
    "examples and datasets. By the end of this book, you will be confident enough to handle a myriad of sources to extract, clean, trnsform, and format your data efficiently.\n",
    "\n",
    "Data science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century. \n",
    "But for all the emphasis on data, it is the science that makes you – the practitioner – truly valuable. \n",
    "\n",
    "To practice high-quality science with data, you need to make sure it is properly sourced, cleaned, formatted, and pre-processed. \n",
    "This book teaches you the most essential basics of this invaluable component of the data science pipeline: data wrangling. In short, data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis. \n",
    "\n",
    "A prominent example of data wrangling with a large amount of data is the one conducted at the Supercomputer Center of University of California \n",
    "San Diego (UCSD). The problem in California is that wildfires are very common, mainly because of the dry weather and extreme heat, especially during the summers. Data\n",
    "scientists at the UCSD Supercomputer Center gather data to predict the nature and spread direction of the fire. The data that comes from \n",
    "diverse sources such as weather stations, sensors in the forest, fire stations, satellite imagery, and Twitter feeds might still be incomplete \n",
    "or missing. This data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mutiline_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2576"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mutiline_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For data to be useful and meaningful, it must be curated and refined. Data Wrangling with Python teaches you all the core ideas behind these processes\\nand equips you with knowledge about the most popular tools and techniques in the domain.\\n\\nThe book starts with the absolute basics of Python, focusing mainly on data structures, and then quickly jumps into the NumPy and pandas libraries \\nas the fundamental tools for data wrangling. We emphasize why you should stay away from the traditional way of data cleaning, as done in other languages, \\nand take advantage of the specialized pre-built routines in Python. Thereafter, you will learn how, using the same Python backend, you can extract and \\ntransform data from a diverse array of\\xa0sources, such as the internet, large database vaults, or Excel financial tables. Then, you will also learn how to handle missing or incorrect data, and reformat it based\\xa0on the requirements from the downstream analytics tool. You will learn about\\xa0these concepts through real-world\\nexamples and datasets. By the end of this book, you will be confident enough to handle a myriad of\\xa0sources to extract, clean, trnsform, and format your data efficiently.\\n\\nData science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century. \\nBut for all the emphasis on data, it is the science that makes you – the practitioner – truly valuable. \\n\\nTo practice high-quality science with data, you need to make sure it is properly sourced, cleaned, formatted, and pre-processed. \\nThis book teaches you the most essential basics of this invaluable component of the data science pipeline: data wrangling. In short, data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis. \\n\\nA prominent example of data wrangling with a large amount of data is the one conducted at the Supercomputer Center of University of California \\nSan Diego (UCSD). The problem in California is that wildfires are very common, mainly because of the dry weather and extreme heat, especially during the summers. Data\\nscientists at the UCSD Supercomputer Center gather data to predict the nature and spread direction of the fire. The data that comes from \\ndiverse sources such as weather stations, sensors in the forest, fire stations, satellite imagery, and Twitter feeds might still be incomplete \\nor missing. This data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutiline_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutiline_text = mutiline_text.replace('\\n', \"\")\n",
    "mutiline_text = mutiline_text.replace('\\xa0', \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For data to be useful and meaningful, it must be curated and refined. Data Wrangling with Python teaches you all the core ideas behind these processesand equips you with knowledge about the most popular tools and techniques in the domain.The book starts with the absolute basics of Python, focusing mainly on data structures, and then quickly jumps into the NumPy and pandas libraries as the fundamental tools for data wrangling. We emphasize why you should stay away from the traditional way of data cleaning, as done in other languages, and take advantage of the specialized pre-built routines in Python. Thereafter, you will learn how, using the same Python backend, you can extract and transform data from a diverse array of sources, such as the internet, large database vaults, or Excel financial tables. Then, you will also learn how to handle missing or incorrect data, and reformat it based on the requirements from the downstream analytics tool. You will learn about these concepts through real-worldexamples and datasets. By the end of this book, you will be confident enough to handle a myriad of sources to extract, clean, trnsform, and format your data efficiently.Data science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century. But for all the emphasis on data, it is the science that makes you – the practitioner – truly valuable. To practice high-quality science with data, you need to make sure it is properly sourced, cleaned, formatted, and pre-processed. This book teaches you the most essential basics of this invaluable component of the data science pipeline: data wrangling. In short, data wrangling is the process that ensures that the data is in a format that is clean, accurate, formatted, and ready to be used for data analysis. A prominent example of data wrangling with a large amount of data is the one conducted at the Supercomputer Center of University of California San Diego (UCSD). The problem in California is that wildfires are very common, mainly because of the dry weather and extreme heat, especially during the summers. Datascientists at the UCSD Supercomputer Center gather data to predict the nature and spread direction of the fire. The data that comes from diverse sources such as weather stations, sensors in the forest, fire stations, satellite imagery, and Twitter feeds might still be incomplete or missing. This data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutiline_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for data to be useful and meaningful it must be curated and refined data wrangling with python teaches you all the core ideas behind these processesand equips you with knowledge about the most popular tools and techniques in the domainthe book starts with the absolute basics of python focusing mainly on data structures and then quickly jumps into the numpy and pandas libraries as the fundamental tools for data wrangling we emphasize why you should stay away from the traditional way of data cleaning as done in other languages and take advantage of the specialized prebuilt routines in python thereafter you will learn how using the same python backend you can extract and transform data from a diverse array of sources such as the internet large database vaults or excel financial tables then you will also learn how to handle missing or incorrect data and reformat it based on the requirements from the downstream analytics tool you will learn about these concepts through realworldexamples and datasets by the end of this book you will be confident enough to handle a myriad of sources to extract clean trnsform and format your data efficientlydata science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century but for all the emphasis on data it is the science that makes you  the practitioner  truly valuable to practice highquality science with data you need to make sure it is properly sourced cleaned formatted and preprocessed this book teaches you the most essential basics of this invaluable component of the data science pipeline data wrangling in short data wrangling is the process that ensures that the data is in a format that is clean accurate formatted and ready to be used for data analysis a prominent example of data wrangling with a large amount of data is the one conducted at the supercomputer center of university of california san diego ucsd the problem in california is that wildfires are very common mainly because of the dry weather and extreme heat especially during the summers datascientists at the ucsd supercomputer center gather data to predict the nature and spread direction of the fire the data that comes from diverse sources such as weather stations sensors in the forest fire stations satellite imagery and twitter feeds might still be incomplete or missing this data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations \n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "# For each string, remove any punctuation characters\n",
    "cleaned_multiline_text = mutiline_text.translate(punctuation)\n",
    "cleaned_multiline_text = cleaned_multiline_text.lower()\n",
    "cleaned_multiline_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for data to be useful and meaningful  it must be curated and refined  data wrangling with python teaches you all the core ideas behind these processesand equips you with knowledge about the most popular tools and techniques in the domain the book starts with the absolute basics of python  focusing mainly on data structures  and then quickly jumps into the numpy and pandas libraries as the fundamental tools for data wrangling  we emphasize why you should stay away from the traditional way of data cleaning  as done in other languages  and take advantage of the specialized pre built routines in python  thereafter  you will learn how  using the same python backend  you can extract and transform data from a diverse array of sources  such as the internet  large database vaults  or excel financial tables  then  you will also learn how to handle missing or incorrect data  and reformat it based on the requirements from the downstream analytics tool  you will learn about these concepts through real worldexamples and datasets  by the end of this book  you will be confident enough to handle a myriad of sources to extract  clean  trnsform  and format your data efficiently data science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century  but for all the emphasis on data  it is the science that makes you   the practitioner   truly valuable  to practice high quality science with data  you need to make sure it is properly sourced  cleaned  formatted  and pre processed  this book teaches you the most essential basics of this invaluable component of the data science pipeline  data wrangling  in short  data wrangling is the process that ensures that the data is in a format that is clean  accurate  formatted  and ready to be used for data analysis  a prominent example of data wrangling with a large amount of data is the one conducted at the supercomputer center of university of california san diego  ucsd   the problem in california is that wildfires are very common  mainly because of the dry weather and extreme heat  especially during the summers  datascientists at the ucsd supercomputer center gather data to predict the nature and spread direction of the fire  the data that comes from diverse sources such as weather stations  sensors in the forest  fire stations  satellite imagery  and twitter feeds might still be incomplete or missing  this data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove special chars, punctuation etc.\n",
    "cleaned_multiline_text = \"\"\n",
    "for char in mutiline_text:\n",
    "    if char == \" \":\n",
    "        cleaned_multiline_text += char\n",
    "    elif char.isalnum():  # using the isalnum() method of strings.\n",
    "        cleaned_multiline_text += char.lower()\n",
    "    else:\n",
    "        cleaned_multiline_text += \" \"\n",
    "cleaned_multiline_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For data to be useful and meaningful it must be curated and refined Data Wrangling with Python teaches you all the core ideas behind these processesand equips you with knowledge about the most popular tools and techniques in the domainThe book starts with the absolute basics of Python focusing mainly on data structures and then quickly jumps into the NumPy and pandas libraries as the fundamental tools for data wrangling We emphasize why you should stay away from the traditional way of data cleaning as done in other languages and take advantage of the specialized pre-built routines in Python Thereafter you will learn how using the same Python backend you can extract and transform data from a diverse array of\\xa0sources such as the internet large database vaults or Excel financial tables Then you will also learn how to handle missing or incorrect data and reformat it based\\xa0on the requirements from the downstream analytics tool You will learn about\\xa0these concepts through real-worldexamples and datasets By the end of this book you will be confident enough to handle a myriad of\\xa0sources to extract clean trnsform and format your data efficientlyData science and analytics are taking over the whole world and the job of a data scientist is routinely being called the coolest job of the 21st century But for all the emphasis on data it is the science that makes you – the practitioner – truly valuable To practice high-quality science with data you need to make sure it is properly sourced cleaned formatted and pre-processed This book teaches you the most essential basics of this invaluable component of the data science pipeline data wrangling In short data wrangling is the process that ensures that the data is in a format that is clean accurate formatted and ready to be used for data analysis A prominent example of data wrangling with a large amount of data is the one conducted at the Supercomputer Center of University of California San Diego (UCSD) The problem in California is that wildfires are very common mainly because of the dry weather and extreme heat especially during the summers Datascientists at the UCSD Supercomputer Center gather data to predict the nature and spread direction of the fire The data that comes from diverse sources such as weather stations sensors in the forest fire stations satellite imagery and Twitter feeds might still be incomplete or missing This data needs to be cleaned and formatted so that it can be used to predict future occurrences of wildfires'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way of doing this (Faster and less code)\n",
    "import re\n",
    "\n",
    "cleaned_multiline_text_2 = re.sub(r'[?|$|.|!|\"|,|;|:]',r'',mutiline_text)\n",
    "cleaned_multiline_text_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above uses Regular Expression. Which will be introduced at a later time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'data',\n",
       " 'to',\n",
       " 'be',\n",
       " 'useful',\n",
       " 'and',\n",
       " 'meaningful',\n",
       " 'it',\n",
       " 'must',\n",
       " 'be',\n",
       " 'curated',\n",
       " 'and',\n",
       " 'refined',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'with',\n",
       " 'python',\n",
       " 'teaches',\n",
       " 'you',\n",
       " 'all',\n",
       " 'the',\n",
       " 'core',\n",
       " 'ideas',\n",
       " 'behind',\n",
       " 'these',\n",
       " 'processesand',\n",
       " 'equips',\n",
       " 'you',\n",
       " 'with',\n",
       " 'knowledge',\n",
       " 'about',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'in',\n",
       " 'the',\n",
       " 'domainthe',\n",
       " 'book',\n",
       " 'starts',\n",
       " 'with',\n",
       " 'the',\n",
       " 'absolute',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'python',\n",
       " 'focusing',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'data',\n",
       " 'structures',\n",
       " 'and',\n",
       " 'then',\n",
       " 'quickly',\n",
       " 'jumps',\n",
       " 'into',\n",
       " 'the',\n",
       " 'numpy',\n",
       " 'and',\n",
       " 'pandas',\n",
       " 'libraries',\n",
       " 'as',\n",
       " 'the',\n",
       " 'fundamental',\n",
       " 'tools',\n",
       " 'for',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'we',\n",
       " 'emphasize',\n",
       " 'why',\n",
       " 'you',\n",
       " 'should',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'traditional',\n",
       " 'way',\n",
       " 'of',\n",
       " 'data',\n",
       " 'cleaning',\n",
       " 'as',\n",
       " 'done',\n",
       " 'in',\n",
       " 'other',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'take',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'the',\n",
       " 'specialized',\n",
       " 'prebuilt',\n",
       " 'routines',\n",
       " 'in',\n",
       " 'python',\n",
       " 'thereafter',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'using',\n",
       " 'the',\n",
       " 'same',\n",
       " 'python',\n",
       " 'backend',\n",
       " 'you',\n",
       " 'can',\n",
       " 'extract',\n",
       " 'and',\n",
       " 'transform',\n",
       " 'data',\n",
       " 'from',\n",
       " 'a',\n",
       " 'diverse',\n",
       " 'array',\n",
       " 'of',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'large',\n",
       " 'database',\n",
       " 'vaults',\n",
       " 'or',\n",
       " 'excel',\n",
       " 'financial',\n",
       " 'tables',\n",
       " 'then',\n",
       " 'you',\n",
       " 'will',\n",
       " 'also',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'missing',\n",
       " 'or',\n",
       " 'incorrect',\n",
       " 'data',\n",
       " 'and',\n",
       " 'reformat',\n",
       " 'it',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'requirements',\n",
       " 'from',\n",
       " 'the',\n",
       " 'downstream',\n",
       " 'analytics',\n",
       " 'tool',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'these',\n",
       " 'concepts',\n",
       " 'through',\n",
       " 'realworldexamples',\n",
       " 'and',\n",
       " 'datasets',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'this',\n",
       " 'book',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'confident',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'a',\n",
       " 'myriad',\n",
       " 'of',\n",
       " 'sources',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'clean',\n",
       " 'trnsform',\n",
       " 'and',\n",
       " 'format',\n",
       " 'your',\n",
       " 'data',\n",
       " 'efficientlydata',\n",
       " 'science',\n",
       " 'and',\n",
       " 'analytics',\n",
       " 'are',\n",
       " 'taking',\n",
       " 'over',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'world',\n",
       " 'and',\n",
       " 'the',\n",
       " 'job',\n",
       " 'of',\n",
       " 'a',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'is',\n",
       " 'routinely',\n",
       " 'being',\n",
       " 'called',\n",
       " 'the',\n",
       " 'coolest',\n",
       " 'job',\n",
       " 'of',\n",
       " 'the',\n",
       " '21st',\n",
       " 'century',\n",
       " 'but',\n",
       " 'for',\n",
       " 'all',\n",
       " 'the',\n",
       " 'emphasis',\n",
       " 'on',\n",
       " 'data',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'science',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'you',\n",
       " 'the',\n",
       " 'practitioner',\n",
       " 'truly',\n",
       " 'valuable',\n",
       " 'to',\n",
       " 'practice',\n",
       " 'highquality',\n",
       " 'science',\n",
       " 'with',\n",
       " 'data',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'it',\n",
       " 'is',\n",
       " 'properly',\n",
       " 'sourced',\n",
       " 'cleaned',\n",
       " 'formatted',\n",
       " 'and',\n",
       " 'preprocessed',\n",
       " 'this',\n",
       " 'book',\n",
       " 'teaches',\n",
       " 'you',\n",
       " 'the',\n",
       " 'most',\n",
       " 'essential',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'this',\n",
       " 'invaluable',\n",
       " 'component',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " 'science',\n",
       " 'pipeline',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'in',\n",
       " 'short',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'that',\n",
       " 'ensures',\n",
       " 'that',\n",
       " 'the',\n",
       " 'data',\n",
       " 'is',\n",
       " 'in',\n",
       " 'a',\n",
       " 'format',\n",
       " 'that',\n",
       " 'is',\n",
       " 'clean',\n",
       " 'accurate',\n",
       " 'formatted',\n",
       " 'and',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'be',\n",
       " 'used',\n",
       " 'for',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'a',\n",
       " 'prominent',\n",
       " 'example',\n",
       " 'of',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'with',\n",
       " 'a',\n",
       " 'large',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " 'is',\n",
       " 'the',\n",
       " 'one',\n",
       " 'conducted',\n",
       " 'at',\n",
       " 'the',\n",
       " 'supercomputer',\n",
       " 'center',\n",
       " 'of',\n",
       " 'university',\n",
       " 'of',\n",
       " 'california',\n",
       " 'san',\n",
       " 'diego',\n",
       " 'ucsd',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'in',\n",
       " 'california',\n",
       " 'is',\n",
       " 'that',\n",
       " 'wildfires',\n",
       " 'are',\n",
       " 'very',\n",
       " 'common',\n",
       " 'mainly',\n",
       " 'because',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dry',\n",
       " 'weather',\n",
       " 'and',\n",
       " 'extreme',\n",
       " 'heat',\n",
       " 'especially',\n",
       " 'during',\n",
       " 'the',\n",
       " 'summers',\n",
       " 'datascientists',\n",
       " 'at',\n",
       " 'the',\n",
       " 'ucsd',\n",
       " 'supercomputer',\n",
       " 'center',\n",
       " 'gather',\n",
       " 'data',\n",
       " 'to',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'and',\n",
       " 'spread',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fire',\n",
       " 'the',\n",
       " 'data',\n",
       " 'that',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'diverse',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'weather',\n",
       " 'stations',\n",
       " 'sensors',\n",
       " 'in',\n",
       " 'the',\n",
       " 'forest',\n",
       " 'fire',\n",
       " 'stations',\n",
       " 'satellite',\n",
       " 'imagery',\n",
       " 'and',\n",
       " 'twitter',\n",
       " 'feeds',\n",
       " 'might',\n",
       " 'still',\n",
       " 'be',\n",
       " 'incomplete',\n",
       " 'or',\n",
       " 'missing',\n",
       " 'this',\n",
       " 'data',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'be',\n",
       " 'cleaned',\n",
       " 'and',\n",
       " 'formatted',\n",
       " 'so',\n",
       " 'that',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'predict',\n",
       " 'future',\n",
       " 'occurrences',\n",
       " 'of',\n",
       " 'wildfires']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize words\n",
    "list_of_words = word_tokenize(cleaned_multiline_text)\n",
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For',\n",
       " 'data',\n",
       " 'to',\n",
       " 'be',\n",
       " 'useful',\n",
       " 'and',\n",
       " 'meaningful',\n",
       " 'it',\n",
       " 'must',\n",
       " 'be',\n",
       " 'curated',\n",
       " 'and',\n",
       " 'refined',\n",
       " 'Data',\n",
       " 'Wrangling',\n",
       " 'with',\n",
       " 'Python',\n",
       " 'teaches',\n",
       " 'you',\n",
       " 'all',\n",
       " 'the',\n",
       " 'core',\n",
       " 'ideas',\n",
       " 'behind',\n",
       " 'these',\n",
       " 'processesand',\n",
       " 'equips',\n",
       " 'you',\n",
       " 'with',\n",
       " 'knowledge',\n",
       " 'about',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'in',\n",
       " 'the',\n",
       " 'domain',\n",
       " 'The',\n",
       " 'book',\n",
       " 'starts',\n",
       " 'with',\n",
       " 'the',\n",
       " 'absolute',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'focusing',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'data',\n",
       " 'structures',\n",
       " 'and',\n",
       " 'then',\n",
       " 'quickly',\n",
       " 'jumps',\n",
       " 'into',\n",
       " 'the',\n",
       " 'NumPy',\n",
       " 'and',\n",
       " 'pandas',\n",
       " 'libraries',\n",
       " 'as',\n",
       " 'the',\n",
       " 'fundamental',\n",
       " 'tools',\n",
       " 'for',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'We',\n",
       " 'emphasize',\n",
       " 'why',\n",
       " 'you',\n",
       " 'should',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'traditional',\n",
       " 'way',\n",
       " 'of',\n",
       " 'data',\n",
       " 'cleaning',\n",
       " 'as',\n",
       " 'done',\n",
       " 'in',\n",
       " 'other',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'take',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'the',\n",
       " 'specialized',\n",
       " 'pre',\n",
       " 'built',\n",
       " 'routines',\n",
       " 'in',\n",
       " 'Python',\n",
       " 'Thereafter',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'using',\n",
       " 'the',\n",
       " 'same',\n",
       " 'Python',\n",
       " 'backend',\n",
       " 'you',\n",
       " 'can',\n",
       " 'extract',\n",
       " 'and',\n",
       " 'transform',\n",
       " 'data',\n",
       " 'from',\n",
       " 'a',\n",
       " 'diverse',\n",
       " 'array',\n",
       " 'of',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'large',\n",
       " 'database',\n",
       " 'vaults',\n",
       " 'or',\n",
       " 'Excel',\n",
       " 'financial',\n",
       " 'tables',\n",
       " 'Then',\n",
       " 'you',\n",
       " 'will',\n",
       " 'also',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'missing',\n",
       " 'or',\n",
       " 'incorrect',\n",
       " 'data',\n",
       " 'and',\n",
       " 'reformat',\n",
       " 'it',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'requirements',\n",
       " 'from',\n",
       " 'the',\n",
       " 'downstream',\n",
       " 'analytics',\n",
       " 'tool',\n",
       " 'You',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'these',\n",
       " 'concepts',\n",
       " 'through',\n",
       " 'real',\n",
       " 'worldexamples',\n",
       " 'and',\n",
       " 'datasets',\n",
       " 'By',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'this',\n",
       " 'book',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'confident',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'a',\n",
       " 'myriad',\n",
       " 'of',\n",
       " 'sources',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'clean',\n",
       " 'trnsform',\n",
       " 'and',\n",
       " 'format',\n",
       " 'your',\n",
       " 'data',\n",
       " 'efficiently',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'analytics',\n",
       " 'are',\n",
       " 'taking',\n",
       " 'over',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'world',\n",
       " 'and',\n",
       " 'the',\n",
       " 'job',\n",
       " 'of',\n",
       " 'a',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'is',\n",
       " 'routinely',\n",
       " 'being',\n",
       " 'called',\n",
       " 'the',\n",
       " 'coolest',\n",
       " 'job',\n",
       " 'of',\n",
       " 'the',\n",
       " '21st',\n",
       " 'century',\n",
       " 'But',\n",
       " 'for',\n",
       " 'all',\n",
       " 'the',\n",
       " 'emphasis',\n",
       " 'on',\n",
       " 'data',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'science',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'you',\n",
       " 'the',\n",
       " 'practitioner',\n",
       " 'truly',\n",
       " 'valuable',\n",
       " 'To',\n",
       " 'practice',\n",
       " 'high',\n",
       " 'quality',\n",
       " 'science',\n",
       " 'with',\n",
       " 'data',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'it',\n",
       " 'is',\n",
       " 'properly',\n",
       " 'sourced',\n",
       " 'cleaned',\n",
       " 'formatted',\n",
       " 'and',\n",
       " 'pre',\n",
       " 'processed',\n",
       " 'This',\n",
       " 'book',\n",
       " 'teaches',\n",
       " 'you',\n",
       " 'the',\n",
       " 'most',\n",
       " 'essential',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'this',\n",
       " 'invaluable',\n",
       " 'component',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " 'science',\n",
       " 'pipeline',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'In',\n",
       " 'short',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'that',\n",
       " 'ensures',\n",
       " 'that',\n",
       " 'the',\n",
       " 'data',\n",
       " 'is',\n",
       " 'in',\n",
       " 'a',\n",
       " 'format',\n",
       " 'that',\n",
       " 'is',\n",
       " 'clean',\n",
       " 'accurate',\n",
       " 'formatted',\n",
       " 'and',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'be',\n",
       " 'used',\n",
       " 'for',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'A',\n",
       " 'prominent',\n",
       " 'example',\n",
       " 'of',\n",
       " 'data',\n",
       " 'wrangling',\n",
       " 'with',\n",
       " 'a',\n",
       " 'large',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " 'is',\n",
       " 'the',\n",
       " 'one',\n",
       " 'conducted',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Supercomputer',\n",
       " 'Center',\n",
       " 'of',\n",
       " 'University',\n",
       " 'of',\n",
       " 'California',\n",
       " 'San',\n",
       " 'Diego',\n",
       " 'UCSD',\n",
       " 'The',\n",
       " 'problem',\n",
       " 'in',\n",
       " 'California',\n",
       " 'is',\n",
       " 'that',\n",
       " 'wildfires',\n",
       " 'are',\n",
       " 'very',\n",
       " 'common',\n",
       " 'mainly',\n",
       " 'because',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dry',\n",
       " 'weather',\n",
       " 'and',\n",
       " 'extreme',\n",
       " 'heat',\n",
       " 'especially',\n",
       " 'during',\n",
       " 'the',\n",
       " 'summers',\n",
       " 'Datascientists',\n",
       " 'at',\n",
       " 'the',\n",
       " 'UCSD',\n",
       " 'Supercomputer',\n",
       " 'Center',\n",
       " 'gather',\n",
       " 'data',\n",
       " 'to',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'and',\n",
       " 'spread',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fire',\n",
       " 'The',\n",
       " 'data',\n",
       " 'that',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'diverse',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'weather',\n",
       " 'stations',\n",
       " 'sensors',\n",
       " 'in',\n",
       " 'the',\n",
       " 'forest',\n",
       " 'fire',\n",
       " 'stations',\n",
       " 'satellite',\n",
       " 'imagery',\n",
       " 'and',\n",
       " 'Twitter',\n",
       " 'feeds',\n",
       " 'might',\n",
       " 'still',\n",
       " 'be',\n",
       " 'incomplete',\n",
       " 'or',\n",
       " 'missing',\n",
       " 'This',\n",
       " 'data',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'be',\n",
       " 'cleaned',\n",
       " 'and',\n",
       " 'formatted',\n",
       " 'so',\n",
       " 'that',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'predict',\n",
       " 'future',\n",
       " 'occurrences',\n",
       " 'of',\n",
       " 'wildfires']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words = cleaned_multiline_text.split()\n",
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21st',\n",
       " 'a',\n",
       " 'about',\n",
       " 'absolute',\n",
       " 'accurate',\n",
       " 'advantage',\n",
       " 'all',\n",
       " 'also',\n",
       " 'amount',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'are',\n",
       " 'array',\n",
       " 'as',\n",
       " 'at',\n",
       " 'away',\n",
       " 'backend',\n",
       " 'based',\n",
       " 'basics',\n",
       " 'be',\n",
       " 'because',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'book',\n",
       " 'but',\n",
       " 'by',\n",
       " 'california',\n",
       " 'called',\n",
       " 'can',\n",
       " 'center',\n",
       " 'century',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaning',\n",
       " 'comes',\n",
       " 'common',\n",
       " 'component',\n",
       " 'concepts',\n",
       " 'conducted',\n",
       " 'confident',\n",
       " 'coolest',\n",
       " 'core',\n",
       " 'curated',\n",
       " 'data',\n",
       " 'database',\n",
       " 'datascientists',\n",
       " 'datasets',\n",
       " 'diego',\n",
       " 'direction',\n",
       " 'diverse',\n",
       " 'domainthe',\n",
       " 'done',\n",
       " 'downstream',\n",
       " 'dry',\n",
       " 'during',\n",
       " 'efficientlydata',\n",
       " 'emphasis',\n",
       " 'emphasize',\n",
       " 'end',\n",
       " 'enough',\n",
       " 'ensures',\n",
       " 'equips',\n",
       " 'especially',\n",
       " 'essential',\n",
       " 'example',\n",
       " 'excel',\n",
       " 'extract',\n",
       " 'extreme',\n",
       " 'feeds',\n",
       " 'financial',\n",
       " 'fire',\n",
       " 'focusing',\n",
       " 'for',\n",
       " 'forest',\n",
       " 'format',\n",
       " 'formatted',\n",
       " 'from',\n",
       " 'fundamental',\n",
       " 'future',\n",
       " 'gather',\n",
       " 'handle',\n",
       " 'heat',\n",
       " 'highquality',\n",
       " 'how',\n",
       " 'ideas',\n",
       " 'imagery',\n",
       " 'in',\n",
       " 'incomplete',\n",
       " 'incorrect',\n",
       " 'internet',\n",
       " 'into',\n",
       " 'invaluable',\n",
       " 'is',\n",
       " 'it',\n",
       " 'job',\n",
       " 'jumps',\n",
       " 'knowledge',\n",
       " 'languages',\n",
       " 'large',\n",
       " 'learn',\n",
       " 'libraries',\n",
       " 'mainly',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'meaningful',\n",
       " 'might',\n",
       " 'missing',\n",
       " 'most',\n",
       " 'must',\n",
       " 'myriad',\n",
       " 'nature',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'numpy',\n",
       " 'occurrences',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'other',\n",
       " 'over',\n",
       " 'pandas',\n",
       " 'pipeline',\n",
       " 'popular',\n",
       " 'practice',\n",
       " 'practitioner',\n",
       " 'prebuilt',\n",
       " 'predict',\n",
       " 'preprocessed',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'processesand',\n",
       " 'prominent',\n",
       " 'properly',\n",
       " 'python',\n",
       " 'quickly',\n",
       " 'ready',\n",
       " 'realworldexamples',\n",
       " 'refined',\n",
       " 'reformat',\n",
       " 'requirements',\n",
       " 'routinely',\n",
       " 'routines',\n",
       " 'same',\n",
       " 'san',\n",
       " 'satellite',\n",
       " 'science',\n",
       " 'scientist',\n",
       " 'sensors',\n",
       " 'short',\n",
       " 'should',\n",
       " 'so',\n",
       " 'sourced',\n",
       " 'sources',\n",
       " 'specialized',\n",
       " 'spread',\n",
       " 'starts',\n",
       " 'stations',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'structures',\n",
       " 'such',\n",
       " 'summers',\n",
       " 'supercomputer',\n",
       " 'sure',\n",
       " 'tables',\n",
       " 'take',\n",
       " 'taking',\n",
       " 'teaches',\n",
       " 'techniques',\n",
       " 'that',\n",
       " 'the',\n",
       " 'then',\n",
       " 'thereafter',\n",
       " 'these',\n",
       " 'this',\n",
       " 'through',\n",
       " 'to',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'traditional',\n",
       " 'transform',\n",
       " 'trnsform',\n",
       " 'truly',\n",
       " 'twitter',\n",
       " 'ucsd',\n",
       " 'university',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'using',\n",
       " 'valuable',\n",
       " 'vaults',\n",
       " 'very',\n",
       " 'way',\n",
       " 'we',\n",
       " 'weather',\n",
       " 'whole',\n",
       " 'why',\n",
       " 'wildfires',\n",
       " 'will',\n",
       " 'with',\n",
       " 'world',\n",
       " 'wrangling',\n",
       " 'you',\n",
       " 'your'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(list_of_words)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_list = list(set(['a','b','c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['refined',\n",
       " 'cleaning',\n",
       " 'but',\n",
       " 'mainly',\n",
       " 'it',\n",
       " 'ucsd',\n",
       " 'practitioner',\n",
       " 'starts',\n",
       " 'specialized',\n",
       " 'as',\n",
       " 'diego',\n",
       " 'sourced',\n",
       " 'a',\n",
       " 'pipeline',\n",
       " 'then',\n",
       " 'quickly',\n",
       " 'transform',\n",
       " 'invaluable',\n",
       " 'during',\n",
       " 'thereafter',\n",
       " 'direction',\n",
       " 'called',\n",
       " 'useful',\n",
       " 'so',\n",
       " 'sources',\n",
       " 'used',\n",
       " 'should',\n",
       " 'or',\n",
       " 'curated',\n",
       " 'into',\n",
       " 'traditional',\n",
       " 'practice',\n",
       " 'stay',\n",
       " 'end',\n",
       " 'needs',\n",
       " 'short',\n",
       " 'reformat',\n",
       " 'century',\n",
       " 'tool',\n",
       " 'common',\n",
       " 'one',\n",
       " 'all',\n",
       " 'datasets',\n",
       " 'prominent',\n",
       " 'array',\n",
       " 'is',\n",
       " 'excel',\n",
       " 'same',\n",
       " 'being',\n",
       " 'coolest',\n",
       " 'preprocessed',\n",
       " 'you',\n",
       " 'wrangling',\n",
       " 'large',\n",
       " 'center',\n",
       " 'libraries',\n",
       " 'formatted',\n",
       " 'concepts',\n",
       " 'satellite',\n",
       " 'knowledge',\n",
       " 'in',\n",
       " 'weather',\n",
       " 'ensures',\n",
       " 'supercomputer',\n",
       " 'and',\n",
       " 'spread',\n",
       " 'fire',\n",
       " 'especially',\n",
       " 'tools',\n",
       " 'imagery',\n",
       " 'the',\n",
       " 'taking',\n",
       " 'need',\n",
       " 'clean',\n",
       " 'example',\n",
       " 'dry',\n",
       " 'future',\n",
       " 'california',\n",
       " 'conducted',\n",
       " 'backend',\n",
       " 'science',\n",
       " 'analysis',\n",
       " 'efficientlydata',\n",
       " 'at',\n",
       " 'to',\n",
       " 'fundamental',\n",
       " 'pandas',\n",
       " 'for',\n",
       " 'prebuilt',\n",
       " 'handle',\n",
       " 'take',\n",
       " 'confident',\n",
       " 'comes',\n",
       " 'gather',\n",
       " 'focusing',\n",
       " 'enough',\n",
       " 'still',\n",
       " 'why',\n",
       " 'routines',\n",
       " 'python',\n",
       " 'core',\n",
       " 'data',\n",
       " 'we',\n",
       " 'based',\n",
       " 'trnsform',\n",
       " 'ready',\n",
       " 'how',\n",
       " 'languages',\n",
       " 'sure',\n",
       " 'highquality',\n",
       " 'are',\n",
       " 'twitter',\n",
       " 'world',\n",
       " 'this',\n",
       " 'very',\n",
       " 'vaults',\n",
       " 'that',\n",
       " 'internet',\n",
       " 'make',\n",
       " 'behind',\n",
       " 'university',\n",
       " 'makes',\n",
       " 'learn',\n",
       " 'these',\n",
       " '21st',\n",
       " 'forest',\n",
       " 'job',\n",
       " 'from',\n",
       " 'incorrect',\n",
       " 'financial',\n",
       " 'your',\n",
       " 'routinely',\n",
       " 'also',\n",
       " 'feeds',\n",
       " 'numpy',\n",
       " 'equips',\n",
       " 'basics',\n",
       " 'on',\n",
       " 'can',\n",
       " 'because',\n",
       " 'san',\n",
       " 'accurate',\n",
       " 'occurrences',\n",
       " 'structures',\n",
       " 'will',\n",
       " 'wildfires',\n",
       " 'popular',\n",
       " 'scientist',\n",
       " 'such',\n",
       " 'extreme',\n",
       " 'stations',\n",
       " 'over',\n",
       " 'done',\n",
       " 'about',\n",
       " 'cleaned',\n",
       " 'using',\n",
       " 'domainthe',\n",
       " 'truly',\n",
       " 'tables',\n",
       " 'sensors',\n",
       " 'format',\n",
       " 'requirements',\n",
       " 'by',\n",
       " 'most',\n",
       " 'analytics',\n",
       " 'techniques',\n",
       " 'emphasize',\n",
       " 'jumps',\n",
       " 'be',\n",
       " 'summers',\n",
       " 'processesand',\n",
       " 'essential',\n",
       " 'incomplete',\n",
       " 'emphasis',\n",
       " 'with',\n",
       " 'datascientists',\n",
       " 'process',\n",
       " 'other',\n",
       " 'problem',\n",
       " 'away',\n",
       " 'ideas',\n",
       " 'valuable',\n",
       " 'predict',\n",
       " 'downstream',\n",
       " 'realworldexamples',\n",
       " 'absolute',\n",
       " 'heat',\n",
       " 'advantage',\n",
       " 'book',\n",
       " 'extract',\n",
       " 'database',\n",
       " 'whole',\n",
       " 'teaches',\n",
       " 'diverse',\n",
       " 'nature',\n",
       " 'properly',\n",
       " 'amount',\n",
       " 'must',\n",
       " 'missing',\n",
       " 'through',\n",
       " 'way',\n",
       " 'might',\n",
       " 'meaningful',\n",
       " 'component',\n",
       " 'myriad',\n",
       " 'of']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use set to get unique words\n",
    "unique_words_as_list = list(unique_words)\n",
    "unique_words_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use dict to do the same\n",
    "unique_words_as_dict = dict.fromkeys(list_of_words)\n",
    "len(list(unique_words_as_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'It': 3,\n",
       " 'is': 12,\n",
       " 'a': 20,\n",
       " 'truth': 2,\n",
       " 'universally': 1,\n",
       " 'acknowledged': 1,\n",
       " 'that': 15,\n",
       " 'single': 3,\n",
       " 'man': 4,\n",
       " 'in': 11,\n",
       " 'possession': 2,\n",
       " 'of': 29,\n",
       " 'good': 3,\n",
       " 'fortune': 3,\n",
       " 'must': 7,\n",
       " 'be': 11,\n",
       " 'want': 3,\n",
       " 'wife': 4,\n",
       " 'However': 1,\n",
       " 'little': 3,\n",
       " 'known': 1,\n",
       " 'the': 17,\n",
       " 'feelings': 1,\n",
       " 'or': 5,\n",
       " 'views': 1,\n",
       " 'such': 5,\n",
       " 'may': 5,\n",
       " 'on': 3,\n",
       " 'his': 11,\n",
       " 'first': 1,\n",
       " 'entering': 1,\n",
       " 'neighbourhood': 3,\n",
       " 'this': 1,\n",
       " 'so': 8,\n",
       " 'well': 1,\n",
       " 'fixed': 1,\n",
       " 'minds': 1,\n",
       " 'surrounding': 1,\n",
       " 'families': 1,\n",
       " 'he': 11,\n",
       " 'considered': 1,\n",
       " 'rightful': 1,\n",
       " 'property': 1,\n",
       " 'some': 2,\n",
       " 'one': 5,\n",
       " 'other': 2,\n",
       " 'their': 1,\n",
       " 'daughters': 4,\n",
       " 'My': 3,\n",
       " 'dear': 8,\n",
       " 'Mr': 10,\n",
       " 'Bennet': 6,\n",
       " 'said': 1,\n",
       " 'lady': 1,\n",
       " 'to': 22,\n",
       " 'him': 4,\n",
       " 'day': 1,\n",
       " 'have': 7,\n",
       " 'you': 24,\n",
       " 'heard': 2,\n",
       " 'Netherfield': 2,\n",
       " 'Park': 1,\n",
       " 'let': 1,\n",
       " 'at': 2,\n",
       " 'last': 2,\n",
       " 'replied': 3,\n",
       " 'had': 3,\n",
       " 'not': 9,\n",
       " 'But': 6,\n",
       " 'it': 11,\n",
       " 'returned': 1,\n",
       " 'she': 6,\n",
       " 'for': 12,\n",
       " 'Mrs': 2,\n",
       " 'Long': 2,\n",
       " 'has': 5,\n",
       " 'just': 1,\n",
       " 'been': 2,\n",
       " 'here': 2,\n",
       " 'and': 17,\n",
       " 'told': 1,\n",
       " 'me': 5,\n",
       " 'all': 3,\n",
       " 'about': 1,\n",
       " 'made': 1,\n",
       " 'no': 7,\n",
       " 'answer': 1,\n",
       " 'Do': 1,\n",
       " 'know': 5,\n",
       " 'who': 1,\n",
       " 'taken': 2,\n",
       " 'cried': 1,\n",
       " 'impatiently': 1,\n",
       " 'You': 7,\n",
       " 'tell': 1,\n",
       " 'I': 17,\n",
       " 'objection': 1,\n",
       " 'hearing': 1,\n",
       " 'This': 1,\n",
       " 'was': 8,\n",
       " 'invitation': 1,\n",
       " 'enough': 1,\n",
       " 'Why': 1,\n",
       " 'my': 10,\n",
       " 'says': 1,\n",
       " 'by': 4,\n",
       " 'young': 2,\n",
       " 'large': 2,\n",
       " 'from': 1,\n",
       " 'north': 1,\n",
       " 'England': 1,\n",
       " 'came': 1,\n",
       " 'down': 1,\n",
       " 'Monday': 1,\n",
       " 'chaise': 1,\n",
       " 'four': 3,\n",
       " 'see': 5,\n",
       " 'place': 1,\n",
       " 'much': 3,\n",
       " 'delighted': 1,\n",
       " 'with': 4,\n",
       " 'agreed': 1,\n",
       " 'Morris': 1,\n",
       " 'immediately': 1,\n",
       " 'take': 2,\n",
       " 'before': 1,\n",
       " 'Michaelmas': 1,\n",
       " 'servants': 1,\n",
       " 'are': 8,\n",
       " 'house': 1,\n",
       " 'end': 1,\n",
       " 'next': 1,\n",
       " 'week': 1,\n",
       " 'What': 2,\n",
       " 'name': 1,\n",
       " 'Bingley': 4,\n",
       " 'Is': 2,\n",
       " 'married': 2,\n",
       " 'Oh': 1,\n",
       " 'Single': 1,\n",
       " 'sure': 2,\n",
       " 'A': 1,\n",
       " 'five': 2,\n",
       " 'thousand': 2,\n",
       " 'year': 2,\n",
       " 'fine': 1,\n",
       " 'thing': 2,\n",
       " 'our': 1,\n",
       " 'girls': 4,\n",
       " 'How': 2,\n",
       " 'can': 4,\n",
       " 'affect': 1,\n",
       " 'them': 11,\n",
       " 'how': 3,\n",
       " 'tiresome': 1,\n",
       " 'am': 2,\n",
       " 'thinking': 2,\n",
       " 'marrying': 2,\n",
       " 'design': 1,\n",
       " 'settling': 1,\n",
       " 'Design': 1,\n",
       " 'Nonsense': 1,\n",
       " 'talk': 1,\n",
       " 'very': 2,\n",
       " 'likely': 1,\n",
       " 'fall': 1,\n",
       " 'love': 1,\n",
       " 'therefore': 1,\n",
       " 'visit': 5,\n",
       " 'as': 7,\n",
       " 'soon': 1,\n",
       " 'comes': 2,\n",
       " 'occasion': 1,\n",
       " 'go': 4,\n",
       " 'send': 2,\n",
       " 'themselves': 1,\n",
       " 'which': 1,\n",
       " 'perhaps': 1,\n",
       " 'will': 9,\n",
       " 'still': 1,\n",
       " 'better': 2,\n",
       " 'handsome': 2,\n",
       " 'any': 1,\n",
       " 'like': 2,\n",
       " 'best': 1,\n",
       " 'party': 1,\n",
       " 'flatter': 1,\n",
       " 'certainly': 1,\n",
       " 'share': 1,\n",
       " 'beauty': 3,\n",
       " 'but': 2,\n",
       " 'do': 4,\n",
       " 'pretend': 1,\n",
       " 'anything': 1,\n",
       " 'extraordinary': 1,\n",
       " 'now': 1,\n",
       " 'When': 2,\n",
       " 'woman': 3,\n",
       " 'grown': 1,\n",
       " 'up': 1,\n",
       " 'ought': 1,\n",
       " 'give': 1,\n",
       " 'over': 3,\n",
       " 'her': 5,\n",
       " 'own': 2,\n",
       " 'In': 1,\n",
       " 'cases': 1,\n",
       " 'often': 1,\n",
       " 'think': 2,\n",
       " 'indeed': 1,\n",
       " 'when': 2,\n",
       " 'into': 2,\n",
       " 'more': 2,\n",
       " 'than': 3,\n",
       " 'engage': 1,\n",
       " 'assure': 2,\n",
       " 'consider': 1,\n",
       " 'your': 3,\n",
       " 'Only': 1,\n",
       " 'what': 2,\n",
       " 'an': 1,\n",
       " 'establishment': 1,\n",
       " 'would': 1,\n",
       " 'Sir': 1,\n",
       " 'William': 1,\n",
       " 'Lady': 1,\n",
       " 'Lucas': 1,\n",
       " 'determined': 1,\n",
       " 'merely': 1,\n",
       " 'account': 1,\n",
       " 'general': 1,\n",
       " 'they': 2,\n",
       " 'newcomers': 1,\n",
       " 'Indeed': 1,\n",
       " 'impossible': 1,\n",
       " 'us': 2,\n",
       " 'if': 2,\n",
       " 'scrupulous': 1,\n",
       " 'surely': 1,\n",
       " 'dare': 1,\n",
       " 'say': 1,\n",
       " 'glad': 1,\n",
       " 'few': 1,\n",
       " 'lines': 1,\n",
       " 'hearty': 1,\n",
       " 'consent': 1,\n",
       " 'whichever': 1,\n",
       " 'chooses': 1,\n",
       " 'though': 1,\n",
       " 'throw': 1,\n",
       " 'word': 1,\n",
       " 'Lizzy': 3,\n",
       " 'desire': 1,\n",
       " 'bit': 1,\n",
       " 'others': 1,\n",
       " 'half': 2,\n",
       " 'Jane': 1,\n",
       " 'nor': 1,\n",
       " 'humoured': 1,\n",
       " 'Lydia': 1,\n",
       " 'always': 1,\n",
       " 'giving': 1,\n",
       " 'preference': 1,\n",
       " 'They': 2,\n",
       " 'none': 1,\n",
       " 'recommend': 1,\n",
       " 'silly': 1,\n",
       " 'ignorant': 1,\n",
       " 'something': 1,\n",
       " 'quickness': 1,\n",
       " 'sisters': 1,\n",
       " 'abuse': 1,\n",
       " 'children': 1,\n",
       " 'way': 1,\n",
       " 'delight': 1,\n",
       " 'vexing': 1,\n",
       " 'compassion': 1,\n",
       " 'poor': 1,\n",
       " 'nerves': 2,\n",
       " 'mistake': 1,\n",
       " 'high': 1,\n",
       " 'respect': 1,\n",
       " 'old': 1,\n",
       " 'friends': 1,\n",
       " 'mention': 1,\n",
       " 'consideration': 1,\n",
       " 'these': 1,\n",
       " 'twenty': 4,\n",
       " 'years': 2,\n",
       " 'least': 1,\n",
       " 'Ah': 1,\n",
       " 'suffer': 1,\n",
       " 'hope': 1,\n",
       " 'get': 2,\n",
       " 'live': 1,\n",
       " 'many': 1,\n",
       " 'men': 1,\n",
       " 'come': 2,\n",
       " 'use': 1,\n",
       " 'should': 1,\n",
       " 'since': 1,\n",
       " 'Depend': 1,\n",
       " 'upon': 1,\n",
       " 'there': 1,\n",
       " 'odd': 1,\n",
       " 'mixture': 1,\n",
       " 'quick': 1,\n",
       " 'parts': 1,\n",
       " 'sarcastic': 1,\n",
       " 'humour': 1,\n",
       " 'reserve': 1,\n",
       " 'caprice': 1,\n",
       " 'experience': 1,\n",
       " 'three': 1,\n",
       " 'insufficient': 1,\n",
       " 'make': 1,\n",
       " 'understand': 1,\n",
       " 'character': 1,\n",
       " 'Her': 1,\n",
       " 'mind': 1,\n",
       " 'less': 1,\n",
       " 'difficult': 1,\n",
       " 'develop': 1,\n",
       " 'She': 1,\n",
       " 'mean': 1,\n",
       " 'understanding': 1,\n",
       " 'information': 1,\n",
       " 'uncertain': 1,\n",
       " 'temper': 1,\n",
       " 'discontented': 1,\n",
       " 'fancied': 1,\n",
       " 'herself': 1,\n",
       " 'nervous': 1,\n",
       " 'The': 1,\n",
       " 'business': 1,\n",
       " 'life': 1,\n",
       " 'its': 1,\n",
       " 'solace': 1,\n",
       " 'visiting': 1,\n",
       " 'news': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in list_of_words:\n",
    "    if unique_words_as_dict[word] is None:\n",
    "        unique_words_as_dict[word] = 1\n",
    "    else:\n",
    "        unique_words_as_dict[word] += 1\n",
    "unique_words_as_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus task: Find the top 25 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = sorted(unique_words_as_dict.items(), key=lambda key_val_tuple: key_val_tuple[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 29),\n",
       " ('you', 24),\n",
       " ('to', 22),\n",
       " ('a', 20),\n",
       " ('the', 17),\n",
       " ('and', 17),\n",
       " ('I', 17),\n",
       " ('that', 15),\n",
       " ('is', 12),\n",
       " ('for', 12),\n",
       " ('in', 11),\n",
       " ('be', 11),\n",
       " ('his', 11),\n",
       " ('he', 11),\n",
       " ('it', 11),\n",
       " ('them', 11),\n",
       " ('Mr', 10),\n",
       " ('my', 10),\n",
       " ('not', 9),\n",
       " ('will', 9),\n",
       " ('so', 8),\n",
       " ('dear', 8),\n",
       " ('was', 8),\n",
       " ('are', 8),\n",
       " ('must', 7)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words[:25]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
